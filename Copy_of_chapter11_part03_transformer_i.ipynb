{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/N-nolwenn/RepositoryTest/blob/main/Copy_of_chapter11_part03_transformer_i.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8mmSXk5Lx48"
      },
      "source": [
        "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
        "\n",
        "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
        "\n",
        "This notebook was generated for TensorFlow 2.6."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASk8VJ1eLx5D"
      },
      "source": [
        "## The Transformer architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting in 2017 the Transformer architecture started overtaking recurrent neural networks across most natural language processing tasks.\n",
        "\n",
        "Proposed in the \"Attention is all you need\" paper: \"neural attention\" could be used to build powerful sequence models."
      ],
      "metadata": {
        "id": "KKONC0nPL6pw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjDXGJ7mLx5F"
      },
      "source": [
        "### Understanding self-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key idea: not all input information seen by a model is equally important to the task at hand so models should \"pay more attention\" to some features and \"pay less attention\" to other features."
      ],
      "metadata": {
        "id": "PBa0WjSgL9wv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The meaning of a word is usually context-specific:\n",
        "\n",
        "\"I'll see you soon\", the meaning of the word \"see\" is subtly different from the \"see\" in 'I'll see this project to its end\" or \"I see what you mean\"\n",
        "\n",
        "Smart embedding space would provide a different vector representation for a word depending on the other words surrounding it. That's where self attention comes in.\n",
        "\n",
        "The purpose of self attention is to modulate the representation of a token by using the representations of related tokens in the sequence."
      ],
      "metadata": {
        "id": "aaRDlABVL_VX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context-aware embedding through self attention:\n",
        "\n",
        "Step1: compute relevancy scores (attention scores) between the vector for \"station\" and every other word in the sentence.\n",
        "\n",
        "Step2: compute the sum of all word vectors in the sentence, weighted by our relevancy scores. Words closely related to \"station\" will contribute more to the sum while irrelevant words will contribute almost nothing\n",
        "\n",
        "Repeat this process for every word in the sentence, producing a new sequence of vectors encoding the sentence."
      ],
      "metadata": {
        "id": "D7O_f_pXMEWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def self_attention(input_sequence):\n",
        "  output=np.zeros(shape=input_sequence.shape)\n",
        "  #step3 for i, pivot_vector in enumerate (input_sequence):#Iterate over each token in the input sequence\n",
        "    #step1\n",
        "  scores=np.zeros(shape=(len(input_sequence),))\n",
        "  for j, vector in enumerate (input_sequence):\n",
        "      scores[j] = np.dot(pivot_vector, vector.T) #Compute the dot product (attention score) betw/ the token and every other token\n",
        "  scores/=np.sqrt(input_sequence.shape[1])\n",
        "  scores=softmax(scores) #end step1\n",
        "    #scale by a normatlization factor and apply a softmax\n",
        "    #step2\n",
        "  new_pivot_representation=np.zeros(shape=pivot_vector.shape)\n",
        "  for j, vector in enumerate(input_sequence):\n",
        "     new_pivot_representation+=vector*score[j] #take the sum of all tokens weighted by the attention scores\n",
        "  output [i]=new_pivot_representation #that sum is our output #end step2\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "FHFViD-PMbVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_heads=4\n",
        "embed_dim=256\n",
        "mha_layer=MultiHeadAttention(num_heads=num_heads, key_dim=embeded_dim)\n",
        "outputs=mha_layer(inputs, inputs, inputs)"
      ],
      "metadata": {
        "id": "8PK9-r8EXMjX",
        "outputId": "89ceb813-2a78-4e57-aa1b-56a7302a46cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1aa866c5c419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0membed_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmha_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeded_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmha_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MultiHeadAttention' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras has built-in layer to handle it: the multiHeadAttention layer"
      ],
      "metadata": {
        "id": "j46NfQn2OGw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why are we passing the inputs to the layer 3 times?\n",
        "\n",
        "What are these \"multiple heads\" we're referring to?"
      ],
      "metadata": {
        "id": "Za1gfbisXiq_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAJ7Yj0PLx5F"
      },
      "source": [
        "#### Generalized self-attention: the query-key-value model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we considered one input sequence but the general case would consider sequence to sequence model (Ex: Machine translation)\n"
      ],
      "metadata": {
        "id": "yBlLDxSzYPzA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=sum(values*pairwise_scores(query, keys))"
      ],
      "metadata": {
        "id": "utN3OxToZGVn",
        "outputId": "9f38b732-658c-4cf2-93cc-5ec03894fcfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-b4a0c9670810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpairwise_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'values' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each token in inputs (A, query \"pivot_vector\") compute how much the token is related to every token in inputs (B, keys, \"vector_T\") and use these scores to weight a sum of tokens from inputs (C, values, \"vector\")"
      ],
      "metadata": {
        "id": "vCLfcEBXZL4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typing up a query to retrieve a photo from your collection \"dogs on the beach\"\n",
        "\n",
        "Each of your pictures in the database is described by a set of keywords \"cat\", \"dog\", \"party\"... We'll call those \"keys\"\n",
        "\n",
        "You've got a reference sequence that describes something you're looking for: the query\n",
        "\n",
        "The search engine will start by comparing your query to the keys in the database.\n",
        "\n",
        "You've got a body of knowledge that you're trying to extract information from: the values\n",
        "\n",
        "you simply match the query to the keys. Then you return a weighted sum of values.\n"
      ],
      "metadata": {
        "id": "M5bLM3PTZPcE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In practice the keys and the values are often the same sequence.\n",
        "\n",
        "In machine translation the query would be the target sequence and the source sequence wouldplay the roles of both keys and values: for each element of the target (like \"tiempo\") you want to go back to the source ('How's the weather today?\") and identify the different bits that are related to it (\"tiempo\" and \"weather\" should have a strong match).\n",
        "\n",
        "In sequence classification then query, keys, and values are all the same: you're comparing a sequence to itselft to enrich token will context from the whole sequence."
      ],
      "metadata": {
        "id": "IudWMYgFZ3ex"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57N4uKE8Lx5G"
      },
      "source": [
        "### Multi-head attention"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The multi head refers to the fact that the output space of the self attention layer gets factored into a set of independent subspaces, learned separately. \n",
        "\n",
        "Having independent heads helps the layer learn different groups of features for each token, where features within one group are correlated with each other but are mostly independent from features in a different group. "
      ],
      "metadata": {
        "id": "KQUQ6iqzadKC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7eQLeLXLx5H"
      },
      "source": [
        "### The Transformer encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The transformer architecture consists of 2 parts: a Transformer encoder that processes the source sequence and a Transformer decoder that uses the source sequence to generate a translated version.\n",
        "\n",
        "If adding extra dense projections is so useful, why don't we also apply one or 2 to the output of the attention mechanism?\n",
        "\n",
        "We might want to add residual connections to make sure we don't destroy any valuable information along the way\n",
        "\n",
        "Normalization layers are supposed to help gradients flow better during backpropagation "
      ],
      "metadata": {
        "id": "fVAEsz5cbA4K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7WmBzTuLx5J"
      },
      "source": [
        "**Getting the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48QtwUd-Lx5K",
        "outputId": "acb52ff4-eb3e-47a2-b318-b2363f28fc8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  21.8M      0  0:00:03  0:00:03 --:--:-- 21.8M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjjZzar7Lx5M"
      },
      "source": [
        "**Preparing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWxa_1AuLx5N",
        "outputId": "6fe3e0d4-17fb-44fb-bbac-ef04bb398714",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import os, pathlib, shutil, random\n",
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = int(0.2 * len(files))\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdJHWjLbLx5P"
      },
      "source": [
        "**Vectorizing the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kj8JgpDLx5P"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUCpLpMlLx5Q"
      },
      "source": [
        "**Transformer encoder implemented as a subclassed `Layer`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LTEG3N_ALx5R"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "class TransformerEncoder(layers.Layer):\n",
        "#DEFINE LAYERS IN HERE\n",
        "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs): \n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim #size of the input token vectors\n",
        "        self.dense_dim = dense_dim #size of the inner dense layer\n",
        "        self.num_heads = num_heads #number of attention heads\n",
        "        self.attention = layers.MultiHeadAttention(\n",
        "            num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.dense_proj = keras.Sequential(\n",
        "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
        "             layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm_1 = layers.LayerNormalization()\n",
        "        self.layernorm_2 = layers.LayerNormalization()\n",
        "\n",
        "#FORWARD PASS\n",
        "    def call(self, inputs, mask=None): #computation goes in call()\n",
        "        if mask is not None: #the mask that will be generated by the embedding layer will be 2D but the attention layer expects to be 3D or 4D so we expand its rank\n",
        "            mask = mask[:, tf.newaxis, :]\n",
        "        attention_output = self.attention(\n",
        "            inputs, inputs, attention_mask=mask) #Here we have 2 inputs, 2 inputs and 3 inputs is the same\n",
        "        proj_input = self.layernorm_1(inputs + attention_output) #residuals connections\n",
        "        proj_output = self.dense_proj(proj_input) #residual connections\n",
        "        return self.layernorm_2(proj_input + proj_output)\n",
        "\n",
        "#WHEN YOU WRITE CUSTOM LAYERS, MAKE SURE TO IMPLEMENT THE get_config method\n",
        "    def get_config(self): #implement serialization so we can save the model\n",
        "        config = super().get_config() #function from layers.Layer class\n",
        "        config.update({\n",
        "            \"embed_dim\": self.embed_dim, #we need memorize them to retrieve the model\n",
        "            \"num_heads\": self.num_heads,\n",
        "            \"dense_dim\": self.dense_dim,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving custom layers\n",
        "\n",
        "get_config method: this enables the layer to be reinstantiated from its config dict, which is useful druing model saving and loading\n",
        "\n",
        "NB: the config does not contain weight values so all weights in the layer get initialized from scratch\n",
        "\n",
        "When saving a model that contains custom layers the savefile will contain these config ficts. When loading the model from the file you should provide the custom layer classes to the loading process so that it can make sens of the config objects"
      ],
      "metadata": {
        "id": "ens5yeSbdS4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Layer normalization\n",
        "\n",
        "Normalization layers we're using here aren't BatchNormalization layers. Were using the LayerNormalization layer, which normalizes each sequence independlty from other sequences in the batch"
      ],
      "metadata": {
        "id": "J2AXQ4OZeWU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def layer_normalization(batch_of_sequences): #input shape: (batch_size, sequence_length, embedding_dim)\n",
        "  mean=np.mean(batch_of_sequences, keepdims=True, axis=-1) #to compute mean and variance we only pool data over the last axis (-1)\n",
        "  variance=np.var(batch_of_sequences, keepdims=True, axis=-1)\n",
        "  return (batch_of_sequences - mean)/variance\n"
      ],
      "metadata": {
        "id": "ezpkGjNOetwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def batch_normalization(batch_of_images):#input shape: (batch_size, height, width, channels)\n",
        "  mean=np.mean(batch_of_images, keepdims=True, axis=0,1,2) #Pool data over the batch axis (0) which creates interactions between samples in a batch\n",
        "  variance=np.var(batch_of_images, keepdims=True, axis=0,1,2)\n",
        "  return (batch_of_images - mean)/variance"
      ],
      "metadata": {
        "id": "7Ez8XFAFfP3o",
        "outputId": "3f0bbd08-22a6-4c4a-ebdd-40100d69c381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-e61c7b61bf63>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    mean=np.mean(batch_of_images, keepdims=True, axis=0,1,2) #Pool data over the batch axis (0) which creates interactions between samples in a batch\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_PJILn9Lx5S"
      },
      "source": [
        "**Using the Transformer encoder for text classification**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mROqn3oiLx5T",
        "outputId": "c92dcfa5-a2c3-4c2a-dbf9-22cc63ecf985",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " transformer_encoder (Transf  (None, None, 256)        543776    \n",
            " ormerEncoder)                                                   \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,664,033\n",
            "Trainable params: 5,664,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "vocab_size = 20000\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x) #Since TransformerEncoder returns full sequences we need to reduce each sequence to a single vector for classification via a global pooling layer\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUlzP9_5Lx5U"
      },
      "source": [
        "**Training and evaluating the Transformer encoder based model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovl4ZAEDLx5U",
        "outputId": "89c56d51-ceb3-45ac-afab-7c32a7b599c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "252/625 [===========>..................] - ETA: 20:01 - loss: 0.6255 - accuracy: 0.6963"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"transformer_encoder.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
        "model = keras.models.load_model(\n",
        "    \"transformer_encoder.keras\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder}) #Provide the custom TransformerEncoder class to the model-loading process\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It gets to 87.5M test accuracy slightly worse than the GRU model"
      ],
      "metadata": {
        "id": "1cQp-hVGguUc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfNRl47vLx5V"
      },
      "source": [
        "#### Using positional encoding to re-inject order information"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer encoder wasn't a sequence model at all. Its composed of dense layers that process sequence tokens independtly from each other and an attention layer that looks at the tokens as a set.\n",
        "\n",
        "Positional encoding: were going to add the word's position in the sequence to each word embedding\n",
        "\n",
        "Simplest scheme would be to concatenate the world's position to its embedding vector. Add a \"position\" axis to the vector and fill it with 0 for the first word in the sequence, 1 for the second and so on\n",
        "\n",
        "However positions can potentially be very large integers, which will disrupt the range of values in the embeddings vector. Neural networks don't like very large input values or discrete input distributions\n",
        "\n",
        "The \"Attention is all you need\" paper used an interesting trick to encode word positions: it added to the word embeddings a vector containing values in the range [-1, 1] that varied cyclically depending on the position (cosine functions)\n",
        "\n",
        "This trick was clever but this is not what we are going to do for now\n",
        "\n",
        "We'll do something simpler and more effective, we'll learn position embedding vectors the same way we learn embed word indices. We'll then proceed to add our position embeddings to the corresponding word embeddings to obtain a position aware word embedding."
      ],
      "metadata": {
        "id": "9uZYHfpdg5NZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltc3Um2ALx5V"
      },
      "source": [
        "**Implementing positional embedding as a subclassed layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using positional encoding to re inject order info"
      ],
      "metadata": {
        "id": "DhXxEMlYiJ0u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nebf2kA5Lx5V"
      },
      "outputs": [],
      "source": [
        "class PositionalEmbedding(layers.Layer):\n",
        "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs): #1\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embeddings = layers.Embedding(#2\n",
        "            input_dim=input_dim, output_dim=output_dim)\n",
        "        self.position_embeddings = layers.Embedding(\n",
        "            input_dim=sequence_length, output_dim=output_dim)#3\n",
        "        self.sequence_length = sequence_length\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "    def call(self, inputs):\n",
        "        length = tf.shape(inputs)[-1]\n",
        "        positions = tf.range(start=0, limit=length, delta=1)\n",
        "        embedded_tokens = self.token_embeddings(inputs)\n",
        "        embedded_positions = self.position_embeddings(positions)\n",
        "        return embedded_tokens + embedded_positions #4\n",
        "\n",
        "    def compute_mask(self, inputs, mask=None):#5\n",
        "        return tf.math.not_equal(inputs, 0)\n",
        "\n",
        "    def get_config(self): #6\n",
        "        config = super().get_config()\n",
        "        config.update({\n",
        "            \"output_dim\": self.output_dim,\n",
        "            \"sequence_length\": self.sequence_length,\n",
        "            \"input_dim\": self.input_dim,\n",
        "        })\n",
        "        return config\n",
        "#1 A Downside of position embeddings is that the sequence lenght needs to be known in advance\n",
        "#2 Prepare an Embedding layer for the token indices\n",
        "#3 And another one for the token positions\n",
        "#4 Add both embedding vectors together\n",
        "#5 Like the Embedding layer, this layer should be able to generate a mask so we can ignore padding 0s in the inputs\n",
        "#The compute_mask method will called automatically by the framework and the mask will get propagated to the next layer\n",
        "#6 Implement serialization so we can save the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nUyNwVJLx5W"
      },
      "source": [
        "#### Putting it all together: A text-classification Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZetpxnjTLx5W"
      },
      "source": [
        "**Combining the Transformer encoder with positional embedding**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZUkljxXLx5W"
      },
      "outputs": [],
      "source": [
        "vocab_size = 20000\n",
        "sequence_length = 600\n",
        "embed_dim = 256\n",
        "num_heads = 2\n",
        "dense_dim = 32\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(inputs) #Looks here! only different line\n",
        "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"full_transformer_encoder.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
        "model = keras.models.load_model(\n",
        "    \"full_transformer_encoder.keras\",\n",
        "    custom_objects={\"TransformerEncoder\": TransformerEncoder,\n",
        "                    \"PositionalEmbedding\": PositionalEmbedding})\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We get to 88.3% test accuracy a solid improvement that clearly demonstrates the value of word order information for text classification. it's still below the bag-of-word approach"
      ],
      "metadata": {
        "id": "NydSZWZYjS1R"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYSTiD2uLx5X"
      },
      "source": [
        "### When to use sequence models over bag-of-words models?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may sometimes hear that bag-of-words methods are outdated and that Transformer based sequence models are the way to go.\n",
        "\n",
        "This is definetly not the case: a small stack of Dense layers on top of a bag-of- bigrams remains a perfectly valid and relevant approach in many cases.\n",
        "\n",
        "Among the various techniques that we've tried on the IMDB dataset throughout this chapter the best performing so far was the bag-of-bigrams!\n",
        "\n",
        "When should you prefer one approach over the other?\n",
        "\n",
        "F Chollet ran a systematic analysis of the performance of various text classification techniques across  many different types of text datasets and they discovered a remarkable and surprising rule of thumb for deciding whether to go with a bag-of-words model or a sequence model."
      ],
      "metadata": {
        "id": "gRWl5nH9HlgZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Bag-of-word VS Transformer model.jpg](data:image/jpeg;base64,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)"
      ],
      "metadata": {
        "id": "qeigNmnbIlP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This intuitively makes sense: the input of a sequence model represents a richer and more complex space and thus it takes more data to map out that space; meanwhile a plain set of terms reside in a simpler space, you can train a logisitic regression on top using just a few hundreds or thousands of samples."
      ],
      "metadata": {
        "id": "LEWfVTMIInFj"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of chapter11_part03_transformer.i",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}